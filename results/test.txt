Loss at iter 1: 0.30383965373039246
Loss at iter 2: 0.2988137900829315
Loss at iter 3: 0.27876749634742737
Loss at iter 4: 0.27922865748405457
Loss at iter 5: 0.28244301676750183
Loss at iter 6: 0.2728545665740967
Loss at iter 7: 0.2731930613517761
Loss at iter 8: 0.27824509143829346
Loss at iter 9: 0.2911502420902252
Loss at iter 10: 0.28763893246650696
Loss at iter 11: 0.2727490961551666
Loss at iter 12: 0.27554208040237427
Loss at iter 13: 0.30041465163230896
Loss at iter 14: 0.26278164982795715
Loss at iter 15: 0.27643030881881714
Loss at iter 16: 0.28815698623657227
Loss at iter 17: 0.2701413929462433
Loss at iter 18: 0.3004615902900696
Loss at iter 19: 0.28235238790512085
Loss at iter 20: 0.2818843126296997
Loss at iter 21: 0.29718050360679626
Loss at iter 22: 0.2689027786254883
Loss at iter 23: 0.258005291223526
Loss at iter 24: 0.2888198792934418
Loss at iter 25: 0.2809789478778839
Loss at iter 26: 0.2929918169975281
Loss at iter 27: 0.27440229058265686
Loss at iter 28: 0.2842833697795868
Loss at iter 29: 0.28101488947868347
Loss at iter 30: 0.2864222228527069
Loss at iter 31: 0.2689550817012787
Loss at iter 32: 0.3089171350002289
Loss at iter 33: 0.2921900749206543
Loss at iter 34: 0.30089619755744934
Loss at iter 35: 0.2825410068035126
Loss at iter 36: 0.2655220329761505
Loss at iter 37: 0.2680034339427948
Loss at iter 38: 0.28478679060935974
Loss at iter 39: 0.2960717976093292
Loss at iter 40: 0.28710484504699707
Loss at iter 41: 0.30840423703193665
Loss at iter 42: 0.2725748121738434
Loss at iter 43: 0.29333043098449707
Loss at iter 44: 0.3064678907394409
Loss at iter 45: 0.2782762944698334
Loss at iter 46: 0.3056621849536896
Loss at iter 47: 0.2872392535209656
Loss at iter 48: 0.26598861813545227
Loss at iter 49: 0.3004160225391388
Loss at iter 50: 0.27358341217041016
Loss at iter 51: 0.26143962144851685
Loss at iter 52: 0.3078386187553406
Loss at iter 53: 0.2656433582305908
Loss at iter 54: 0.2639409005641937
Loss at iter 55: 0.2740604877471924
Loss at iter 56: 0.2753309905529022
Loss at iter 57: 0.28037014603614807
Loss at iter 58: 0.27496105432510376
Loss at iter 59: 0.27958449721336365
Loss at iter 60: 0.2871003746986389
Loss at iter 61: 0.2904229462146759
Loss at iter 62: 0.2865302264690399
Loss at iter 63: 0.3096374571323395
Loss at iter 64: 0.28457438945770264
Loss at iter 65: 0.2982458472251892
Loss at iter 66: 0.29306918382644653
Loss at iter 67: 0.2827740013599396
Loss at iter 68: 0.2794414162635803
Loss at iter 69: 0.2706214189529419
Loss at iter 70: 0.2603478729724884
Loss at iter 71: 0.3089798390865326
Loss at iter 72: 0.2836717665195465
Loss at iter 73: 0.2878511846065521
Loss at iter 74: 0.30080705881118774
Loss at iter 75: 0.2675181031227112
Loss at iter 76: 0.2771352231502533
Loss at iter 77: 0.2825563848018646
Loss at iter 78: 0.2921980023384094
Loss at iter 79: 0.28414782881736755
Loss at iter 80: 0.290174275636673
Loss at iter 81: 0.29424411058425903
Loss at iter 82: 0.30083200335502625
Loss at iter 83: 0.2932317852973938
Loss at iter 84: 0.2799297869205475
Loss at iter 85: 0.2808227837085724
Loss at iter 86: 0.2658780515193939
Loss at iter 87: 0.28493624925613403
Loss at iter 88: 0.28131189942359924
Loss at iter 89: 0.2823386788368225
Loss at iter 90: 0.2921343743801117
Loss at iter 91: 0.3061031997203827
Loss at iter 92: 0.28284361958503723
Loss at iter 93: 0.28430312871932983
Loss at iter 94: 0.2743077874183655
Loss at iter 95: 0.2728610932826996
Loss at iter 96: 0.28432023525238037
Loss at iter 97: 0.2735355794429779
Loss at iter 98: 0.26966819167137146
Loss at iter 99: 0.28552040457725525
Loss at iter 100: 0.30094000697135925
Loss at iter 101: 0.2577061057090759
